{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e21090",
   "metadata": {},
   "source": [
    "The unsloth Python library is a relatively new open-source library designed to make working with large language models (LLMs) easier, faster, and more memory-efficient, particularly for fine-tuning and inference tasks on consumer-grade hardware (like a single GPU with limited VRAM).\n",
    "Key Features of unsloth:\n",
    "\n",
    "1. **Optimized Fine-Tuning**:\n",
    "\n",
    "    - It allows efficient fine-tuning of LLMs using techniques like QLoRA (Quantized Low-Rank Adapter) and LoRA (Low-Rank Adaptation).\n",
    "    - Supports 4-bit and 8-bit quantization, which significantly reduces memory usage without severely impacting performance.\n",
    "\n",
    "1. **Speed & Efficiency**:\n",
    "\n",
    "    - The library claims to be 2x faster than Hugging Face Transformers for fine-tuning models like LLaMA, Mistral, etc.\n",
    "    - It is optimized for single-GPU setups, even with as little as 16 GB of VRAM.\n",
    "\n",
    "1. **Easy-to-Use API**:\n",
    "\n",
    "    - Offers a familiar API similar to Hugging Face Transformers, making it easy to switch or integrate.\n",
    "    - Built-in training, evaluation, and model loading utilities.\n",
    "\n",
    "1. **Compatibility**:\n",
    "\n",
    "    - Integrates well with Hugging Faceâ€™s ecosystem (e.g., ðŸ¤— Datasets, Accelerate, Transformers).\n",
    "    - Supports popular open LLMs such as LLaMA, Mistral, Gemma, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae67c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Desktop/lezioni/11_Transformers/Ollama_finetuning/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.5.7: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A30 MIG 4g.24gb. Num GPUs = 1. Max memory: 23.486 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection.\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage.\n",
    "\n",
    "# Loading the pre-trained model - LLAMA 3 8b\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # bnb means BitsandBytes, a library for model quantization\n",
    "    model_name = \"unsloth/llama-3-8b-bnb-4bit\", # More models at https://huggingface.co/unsloth\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9845fc",
   "metadata": {},
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db0e3d",
   "metadata": {},
   "source": [
    "Instead of updating the original large weight matrices $W$ in layers (e.g., attention layers), LoRA freezes them and adds small trainable low-rank matrices ($A$ and $B$) as an approximation:\n",
    "\n",
    "$$\n",
    "    W_{adapted} = W + \\alpha (AB)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $W$ it the original pretrained weights (frozen)\n",
    "- $A$ and $B$ are the low-rank matrices (trainable, much smaller)\n",
    "- $\\alpha$ is a scaling factor\n",
    "\n",
    "By using low-rank matrices (e.g., rank $r=8$), LoRA significantly reduces:\n",
    "- Memory usage\n",
    "- Number of trainable parameters\n",
    "- Time to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d9633e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.5.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    # The rank of the finetuning process\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    # Modules to finetune. We selected all modules (recommanded)\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    # The scaling factor for finetuning.\n",
    "    # A larger number will make the finetune learn more about your dataset, but can promote over-fitting.\n",
    "    # suggest equal to rank r, or double it.\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # Unsloth Gradient Checkpointing algorithm that enables fine-tuning LLMs with exceptionally long context windows\n",
    "    # It uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    # Advanced feature to set automatically the 'lora_alpha' parameter\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    # Advanced feature to initialize the LoRA matrices to the top r singular vectors of the weights.\n",
    "    # Can improve accuracy somewhat, but can make memory usage explode at the start.\n",
    "    loftq_config = None, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a86527",
   "metadata": {},
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n",
    "We now use the Alpaca dataset from [vicgalle](https://huggingface.co/datasets/vicgalle/alpaca-gpt4), which is a version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html) generated from GPT4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43674770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instruction', 'input', 'output', 'text']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"vicgalle/alpaca-gpt4\", split=\"train\")\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe3a2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3ca9b",
   "metadata": {},
   "source": [
    "One issue is this dataset has multiple columns. For `Ollama` and `llama.cpp` to function like a custom `ChatGPT` Chatbot, we must only have 2 columns - an `instruction` and an `output` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cdbf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instruction', 'input', 'output', 'text']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6966c7",
   "metadata": {},
   "source": [
    "To solve this, we shall do the following:\n",
    "* Merge all columns into 1 instruction prompt.\n",
    "* Remember LLMs are text predictors, so we can customize the instruction to anything we like!\n",
    "* Use the `to_sharegpt` function to do this column merging process!\n",
    "\n",
    "For example below in our [Titanic CSV finetuning notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb), we merged multiple columns in 1 prompt:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/unslothai/unsloth/nightly/images/Merge.png\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0c73d",
   "metadata": {},
   "source": [
    "To merge multiple columns into 1, use `merged_prompt`.\n",
    "* Enclose all columns in curly braces `{}`.\n",
    "* Optional text must be enclused in `[[]]`. For example if the column \"Pclass\" is empty, the merging function will not show the text and skp this. This is useful for datasets with missing values.\n",
    "* You can select every column, or a few!\n",
    "* Select the output or target / prediction column in `output_column_name`. For the Alpaca dataset, this will be `output`.\n",
    "\n",
    "To make the finetune handle multiple turns (like in ChatGPT), we have to create a \"fake\" dataset with multiple turns - we use `conversation_extension` to randomnly select some conversations from the dataset, and pack them together into 1 conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9b9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import to_sharegpt\n",
    "\n",
    "dataset = to_sharegpt(\n",
    "    dataset,\n",
    "    merged_prompt=\"{instruction}[[\\nYour input is:\\n{input}]]\",\n",
    "    output_column_name=\"output\",\n",
    "    conversation_extension=3,  # Select more to handle longer conversations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5294d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['conversations'],\n",
      "    num_rows: 52002\n",
      "})\n",
      "{'conversations': [{'from': 'human', 'value': 'Give three tips for staying healthy.'}, {'from': 'gpt', 'value': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'}, {'from': 'human', 'value': 'Describe what a monotheistic religion is.'}, {'from': 'gpt', 'value': 'A monotheistic religion is a type of religion that believes in the existence of only one supreme and all-powerful deity, who is considered the creator and ruler of the universe. This deity is worshiped as the ultimate and only divine being, and followers of such religions often see their deity as omniscient, omnipotent, and omnibenevolent. Some of the most widely practiced monotheistic religions in the world today include Christianity, Islam, and Judaism, among others. The concept of monotheism differs from polytheism, which believes in the existence of multiple gods, and from atheism, which denies the existence of any deity.'}, {'from': 'human', 'value': 'How does one add a chart to a document?'}, {'from': 'gpt', 'value': 'To add a chart to a document, follow these steps:\\n\\n1. Open the document where you want to insert the chart.\\n2. Click the location where you want to insert the chart.\\n3. In most word processors, you can go to the **Insert** tab, where you can find a **Chart** option. Click on it.\\n4. A new window will appear, and you\\'ll be able to select the chart type that you want to use (column, pie, line, bar, area, scatter, etc.).\\n5. Once you\\'ve selected your chart type, youâ€™ll be prompted to enter your data into a spreadsheet. You can either type your data in manually or copy it from an existing data source.\\n6. Edit your chart data and customize its appearance to fit your document\\'s style or branding.\\n7. When youâ€™re happy with how the chart looks, click \"OK\" or \"Insert\" to add the chart to your document.\\n8. Optionally, you can add a chart title or labels to the axes to make the chart easier to understand.\\n\\nThese instructions may vary depending on the type of word processor you are using.'}]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3413757",
   "metadata": {},
   "source": [
    "Finally use `standardize_sharegpt` to fix up the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425e5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import standardize_sharegpt\n",
    "\n",
    "dataset = standardize_sharegpt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6756fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['conversations'],\n",
      "    num_rows: 52002\n",
      "})\n",
      "{'conversations': [{'content': 'Give three tips for staying healthy.', 'role': 'user'}, {'content': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.', 'role': 'assistant'}, {'content': 'Describe what a monotheistic religion is.', 'role': 'user'}, {'content': 'A monotheistic religion is a type of religion that believes in the existence of only one supreme and all-powerful deity, who is considered the creator and ruler of the universe. This deity is worshiped as the ultimate and only divine being, and followers of such religions often see their deity as omniscient, omnipotent, and omnibenevolent. Some of the most widely practiced monotheistic religions in the world today include Christianity, Islam, and Judaism, among others. The concept of monotheism differs from polytheism, which believes in the existence of multiple gods, and from atheism, which denies the existence of any deity.', 'role': 'assistant'}, {'content': 'How does one add a chart to a document?', 'role': 'user'}, {'content': 'To add a chart to a document, follow these steps:\\n\\n1. Open the document where you want to insert the chart.\\n2. Click the location where you want to insert the chart.\\n3. In most word processors, you can go to the **Insert** tab, where you can find a **Chart** option. Click on it.\\n4. A new window will appear, and you\\'ll be able to select the chart type that you want to use (column, pie, line, bar, area, scatter, etc.).\\n5. Once you\\'ve selected your chart type, youâ€™ll be prompted to enter your data into a spreadsheet. You can either type your data in manually or copy it from an existing data source.\\n6. Edit your chart data and customize its appearance to fit your document\\'s style or branding.\\n7. When youâ€™re happy with how the chart looks, click \"OK\" or \"Insert\" to add the chart to your document.\\n8. Optionally, you can add a chart title or labels to the axes to make the chart easier to understand.\\n\\nThese instructions may vary depending on the type of word processor you are using.', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5d775",
   "metadata": {},
   "source": [
    "### Customizable Chat Templates\n",
    "\n",
    "You also need to specify a chat template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488158f",
   "metadata": {},
   "source": [
    "Now, you have to use `{INPUT}` for the instruction and `{OUTPUT}` for the response.\n",
    "\n",
    "We also allow you to use an optional `{SYSTEM}` field. This is useful for Ollama when you want to use a custom system prompt (also like in ChatGPT).\n",
    "\n",
    "You can also not put a `{SYSTEM}` field, and just put plain text.\n",
    "\n",
    "```python\n",
    "chat_template = \"\"\"{SYSTEM}\n",
    "USER: {INPUT}\n",
    "ASSISTANT: {OUTPUT}\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d103fe0b",
   "metadata": {},
   "source": [
    "The issue is the Alpaca format has 3 fields, whilst OpenAI style chatbots must only use 2 fields (instruction and response). That's why we used the `to_sharegpt` function to merge these columns into 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac881bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We automatically added an EOS token to stop endless generations.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52002/52002 [00:03<00:00, 17280.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "chat_template = \"\"\"Below are some instructions that describe some tasks. Write responses that appropriately complete each request.\n",
    "\n",
    "### Instruction:\n",
    "{INPUT}\n",
    "\n",
    "### Response:\n",
    "{OUTPUT}\"\"\"\n",
    "\n",
    "from unsloth import apply_chat_template\n",
    "\n",
    "dataset = apply_chat_template(\n",
    "    dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    chat_template=chat_template,\n",
    "    # default_system_message = \"You are a helpful assistant\", << [OPTIONAL]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c55ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conversations', 'text']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': 'Give three tips for staying healthy.', 'role': 'user'},\n",
       " {'content': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Describe what a monotheistic religion is.', 'role': 'user'},\n",
       " {'content': 'A monotheistic religion is a type of religion that believes in the existence of only one supreme and all-powerful deity, who is considered the creator and ruler of the universe. This deity is worshiped as the ultimate and only divine being, and followers of such religions often see their deity as omniscient, omnipotent, and omnibenevolent. Some of the most widely practiced monotheistic religions in the world today include Christianity, Islam, and Judaism, among others. The concept of monotheism differs from polytheism, which believes in the existence of multiple gods, and from atheism, which denies the existence of any deity.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'How does one add a chart to a document?', 'role': 'user'},\n",
       " {'content': 'To add a chart to a document, follow these steps:\\n\\n1. Open the document where you want to insert the chart.\\n2. Click the location where you want to insert the chart.\\n3. In most word processors, you can go to the **Insert** tab, where you can find a **Chart** option. Click on it.\\n4. A new window will appear, and you\\'ll be able to select the chart type that you want to use (column, pie, line, bar, area, scatter, etc.).\\n5. Once you\\'ve selected your chart type, youâ€™ll be prompted to enter your data into a spreadsheet. You can either type your data in manually or copy it from an existing data source.\\n6. Edit your chart data and customize its appearance to fit your document\\'s style or branding.\\n7. When youâ€™re happy with how the chart looks, click \"OK\" or \"Insert\" to add the chart to your document.\\n8. Optionally, you can add a chart title or labels to the axes to make the chart easier to understand.\\n\\nThese instructions may vary depending on the type of word processor you are using.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Below are some instructions that describe some tasks. Write responses that appropriately complete each request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|end_of_text|>\\n\\n### Instruction:\\nDescribe what a monotheistic religion is.\\n\\n### Response:\\nA monotheistic religion is a type of religion that believes in the existence of only one supreme and all-powerful deity, who is considered the creator and ruler of the universe. This deity is worshiped as the ultimate and only divine being, and followers of such religions often see their deity as omniscient, omnipotent, and omnibenevolent. Some of the most widely practiced monotheistic religions in the world today include Christianity, Islam, and Judaism, among others. The concept of monotheism differs from polytheism, which believes in the existence of multiple gods, and from atheism, which denies the existence of any deity.<|end_of_text|>\\n\\n### Instruction:\\nHow does one add a chart to a document?\\n\\n### Response:\\nTo add a chart to a document, follow these steps:\\n\\n1. Open the document where you want to insert the chart.\\n2. Click the location where you want to insert the chart.\\n3. In most word processors, you can go to the **Insert** tab, where you can find a **Chart** option. Click on it.\\n4. A new window will appear, and you\\'ll be able to select the chart type that you want to use (column, pie, line, bar, area, scatter, etc.).\\n5. Once you\\'ve selected your chart type, youâ€™ll be prompted to enter your data into a spreadsheet. You can either type your data in manually or copy it from an existing data source.\\n6. Edit your chart data and customize its appearance to fit your document\\'s style or branding.\\n7. When youâ€™re happy with how the chart looks, click \"OK\" or \"Insert\" to add the chart to your document.\\n8. Optionally, you can add a chart title or labels to the axes to make the chart easier to understand.\\n\\nThese instructions may vary depending on the type of word processor you are using.<|end_of_text|>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.column_names)\n",
    "display(dataset[0]['conversations'])\n",
    "display(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653b5b0",
   "metadata": {},
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d726b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52002/52002 [00:21<00:00, 2379.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2, # Number of processes to use for processing the dataset.\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2, # Batch size per device\n",
    "        # Number of updates steps to accumulate the gradients for, before performing a backward/update pass.\n",
    "        gradient_accumulation_steps = 4,\n",
    "        # warmup_steps defines the number of initial training steps during which the learning rate increases linearly\n",
    "        # from a very small value (usually 0) to the target learning rate.\n",
    "        # After this warmup period, the learning rate typically decays according to a chosen scheduler (e.g. linear, cosine).\n",
    "        # Fine-tuning LLMs can be unstable, especially at the beginning. Jumping straight to a high learning rate can cause\n",
    "        # problems. This helps to stabilize the training phase\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,\n",
    "        # num_train_epochs = 1, # For longer training runs!\n",
    "        learning_rate = 2e-4,\n",
    "        # use fp16-bit values instead of 32-bit\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        # use bf16-bit values instead of 32-bit\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        # weight_decay is a regularization technique used during training to\n",
    "        # help prevent overfitting by discouraging the optimizer from assigning large weights.\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed2b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 52,002 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:36, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.353800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.259400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.068600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.067300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.166200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.997800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.236200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.081300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.034100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd06f14",
   "metadata": {},
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model! Unsloth makes inference natively 2x faster as well! You should use prompts which are similar to the ones you had finetuned on, otherwise you might get bad results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bf67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next number in the Fibonacci sequence is 13.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "messages = [                    # Change below!\n",
    "    {\"role\": \"user\", \"content\": \"Continue the fibonacci sequence! Your input is 1, 1, 2, 3, 5, 8,\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# prints to stdout tokens\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dbb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tallest tower in France is called the Tour Eiffel, also known as the Eiffel Tower. It was built in 1889 for the World's Fair and stands at a height of 324 meters (1,063 feet).<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "messages = [                         # Change below!\n",
    "    {\"role\": \"user\",      \"content\": \"Continue the fibonacci sequence! Your input is 1, 1, 2, 3, 5, 8\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The fibonacci sequence continues as 13, 21, 34, 55 and 89.\"},\n",
    "    {\"role\": \"user\",      \"content\": \"What is France's tallest tower called?\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
