{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gg-L3oUTlaHI"
   },
   "source": [
    "# Convolutional Neural Netowrk to predict images from CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Y-2fDwlx1p"
   },
   "source": [
    "In this lecture we are going to learn about CNN (Convolutional Neural Networks).\n",
    "We will learn how to build and how to use them to make predictions.\n",
    "\n",
    "The dataset of today's classification task is: CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C--TtAiXnIgI"
   },
   "source": [
    "### Dataset loading and some data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJJPqhTAkQZa",
    "outputId": "0293076e-f12b-4501-af01-7e984f477ac7"
   },
   "outputs": [],
   "source": [
    "# TODO: loading CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = ...\n",
    "\n",
    "# print dataset shape and a single image shape\n",
    "print(\"Train dataset shape:\", x_train.shape)\n",
    "print(\"Single image shape:\", x_train[0].shape)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = ...\n",
    "x_test =  ...\n",
    "\n",
    "print(\"Train label shape:\", y_train.shape)\n",
    "print(\"Unique labels: \", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "MZNooFcqXMnQ",
    "outputId": "6d063351-033e-4d7a-8e99-d62a5dac9dca"
   },
   "outputs": [],
   "source": [
    "# We plot the first 25 images in the dataset (in a grid 5x5) with the corresponding labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',     # We add the dataset labels just to understand better the output.\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']             # They are provided in the dataset documentation\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(class_names[y_train[i][0]], fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haIBLBbDnNqh"
   },
   "source": [
    "## Building the CNN\n",
    "\n",
    "We are going to create a CNN model having these hidden layers:\n",
    "1. `layer1`: conv2D having 32 filters of size 3x3, stride=1, ReLu activation, padding \"same\"\n",
    "2. `layer2`: maxPool with filter size 2x2 and stride=1\n",
    "3. `layer3`: conv2D having 64 filters of size 3x3, stride=1, ReLu activation, padding \"same\"\n",
    "4. `layer4`: maxPool with filter size 2x2 and stride=1\n",
    "5. `layer5`: conv2D having 64 filters of size 3x3, stride=1, ReLu activation, padding \"same\"\n",
    "6. `layer6`: maxPool with filter size 2x2 and stride=1\n",
    "7. `layer7`: MLP with 64 nodes\n",
    "\n",
    "- **Keras sequential** documentation: https://keras.io/guides/sequential_model/\n",
    "- **Keras documentation for Conv2D** class: https://keras.io/api/layers/convolution_layers/convolution2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kmBHPdokdK_",
    "outputId": "b64d823d-9843-41f2-b894-8d5219a0b5c7"
   },
   "outputs": [],
   "source": [
    "# TODO: define the CNN model as described\n",
    "# HINT: pay attention when you are coding the 6th-7th layer, we need something in between !\n",
    "model = Sequential([\n",
    "    ...\n",
    "])\n",
    "\n",
    "# Model architecture visualization\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp-f3SU2nxhK"
   },
   "source": [
    "#### Visualize and plot the model architeture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPy-4DnoMULn",
    "outputId": "145a3172-2937-4ab5-ae82-911576b81288"
   },
   "outputs": [],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "LvdUgQOYMULo",
    "outputId": "79f49405-1f29-4656-e664-9b63cb24d54b"
   },
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='output.png') # write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "id": "VAqgf6m1MULo",
    "outputId": "a47404e0-d4ab-42e9-f5bf-c99f886a284c"
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKBUiq04MULp"
   },
   "source": [
    "### CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cit5H67RkmA-",
    "outputId": "6ab0095b-0b23-4a5a-93ee-0a66189e98a1"
   },
   "outputs": [],
   "source": [
    "# TODO: compile the model as follows:\n",
    "#       - use Adam optimizer\n",
    "#       - use Sparse Categorical Crossentripy loss\n",
    "#       - add the Accuracy metric\n",
    "#\n",
    "# NOTE: Sparse Categorical Crossentropy is similar to Categorical Crossentropy but is designed for cases\n",
    "#       where the target labels are not one-hot encoded. Instead, the labels are represented as integers\n",
    "#       corresponding to the class indices. The true labels are integers, where each integer represents the class index.\n",
    "...\n",
    "\n",
    "# TODO: train the Model for 15 epochs\n",
    "history = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MkZY9xHoBWL"
   },
   "source": [
    "### CNN evaluation\n",
    "\n",
    "- All the training data have been stored in a **History** object.\n",
    "- Its `History.history` attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values.\n",
    "- If you don't remember how history is made you can run\n",
    "    ```python\n",
    "    type(history.history)\n",
    "    ```\n",
    "- Moreover, since it is a dictionary (a structure key:value) you can list the metrics stored in history (the keys) using\n",
    "    ```python\n",
    "    history.history.keys()\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMLqPyf_odUu"
   },
   "source": [
    "**Model evaluation**\n",
    "\n",
    "In order to evaluate our model we want to:\n",
    "- plot accuracy curve on training and validation sets\n",
    "- test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "BPhCeIHMMULq",
    "outputId": "f988f488-ccaf-4c8e-b7f4-c76d38cf7b4d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Degine a subplot grid 1x2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Plot for loss and val_loss\n",
    "plt.title(\"Loss Function\")\n",
    "plt.plot(..., label='loss')\n",
    "plt.xlabel('Epoch', fontsize=13)\n",
    "plt.ylabel('Loss', fontsize=13)\n",
    "plt.ylim([0.0, 2])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Plot for accuracy and val_accuracy\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(..., label='accuracy', color='tab:orange')\n",
    "plt.xlabel('Epoch', fontsize=13)\n",
    "plt.ylabel('Accuracy', fontsize=13)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pYmIEmflOv6",
    "outputId": "6e8327e8-ffc8-43bf-dcc3-0a66979b8266"
   },
   "outputs": [],
   "source": [
    "# TODO: evaluate the Model on test data\n",
    "test_loss, test_accuracy = ...\n",
    "\n",
    "print(f'Loss on test set: {test_loss}')\n",
    "print(f'Accuracy on test set: {test_accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shIcgv4qo-Ad"
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "- A confusion matrix is a performance measurement tool used in classification tasks, to evaluate the performance of a classification model.\n",
    "- It is a square matrix where each row represents the instances in a predicted class, and each column represents the instances in an actual class (or vice versa).\n",
    "- The diagonal elements of the matrix represent the number of correct predictions for each class, while the off-diagonal elements represent incorrect predictions.\n",
    "\n",
    "By analyzing the confusion matrix, we can gain insights into the model's performance, such as:\n",
    "- `Accuracy`: The overall accuracy of the model, calculated as the ratio of the sum of correct predictions to the total number of predictions.\n",
    "- `Precision`: The ratio of true positive predictions to the total number of positive predictions, indicating the model's ability to correctly identify positive cases.\n",
    "- `Recall`: The ratio of true positive predictions to the total number of actual positive cases, indicating the model's ability to capture all positive cases.\n",
    "- `F1 Score`: The harmonic mean of precision and recall, providing a balance between the two metrics.\n",
    "\n",
    "Overall, the confusion matrix provides a comprehensive overview of the model's performance across different classes, enabling us to identify areas for improvement and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn    # https://seaborn.pydata.org/\n",
    "import pandas  as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "uHpu4LeXg90X",
    "outputId": "a9ed37a7-8229-437e-c22f-c0f48d80d9e6"
   },
   "outputs": [],
   "source": [
    "# TODO: get model prediction on testing set\n",
    "y_pred = ...\n",
    "\n",
    "# TODO compute the confusion matrix\n",
    "# HINT: use the confusion_matrix function provided by sklear lib\n",
    "matrix = ...\n",
    "\n",
    "# We plot the confusion matrix\n",
    "df_cm = pd.DataFrame(matrix, class_names, class_names)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4) #for label size\n",
    "sn.heatmap(df_cm, cmap=\"BuPu\",annot=True,annot_kws={\"size\": 10})# font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save the Model\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUm1EgnPpSli"
   },
   "source": [
    "### **Visualize the feature maps**\n",
    "Feature maps are the **representations of features extracted from the input image at each level of the CNN**.\n",
    "\n",
    "To visualize the latent features computed by a convolutional layer for a given image, you have to extract the output values of that layer.\n",
    "\n",
    "To do this:\n",
    "- you need to create a new model with the same input as the original model and the layer you want to analyze as the output layer.\n",
    "- once you have this new model, you can call it on the image you want to visualize, and it will output the feature maps for that specific layer.\n",
    "\n",
    "This can help you understand what features the model is detecting in the image and how it is processing the input data.\n",
    "\n",
    "To access the layers, you can use  `model.layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpOCqCAvhCXS",
    "outputId": "d390b3da-31c4-4355-c411-ddfcdc6cfb3e"
   },
   "outputs": [],
   "source": [
    "# TODO: print some layers\n",
    "print(type(model.layers))\n",
    "print(model.layers[0])\n",
    "\n",
    "# TODO: print only the conv layers\n",
    "for ...:\n",
    "\t...\n",
    "\t\t..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiGrJkoYMULr"
   },
   "source": [
    "1. Show the feature maps extracted by the first conv layer\n",
    "2. Build a new model to output right after the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4p7MVtOHhE9K",
    "outputId": "b5aba8b7-b519-4fe8-ce45-23fdc5e79c91"
   },
   "outputs": [],
   "source": [
    "# We create a new model with the first conv layer as output\n",
    "# NOTE: You can get the model by its name, but consider that the names assigned change if you re-run the code so\n",
    "#       it's better to select the layer using the list index\n",
    "model_v = keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "model_v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6H_oRsZvhH8_",
    "outputId": "dc7b1e26-a515-41ef-adfd-a05a7ea34f52"
   },
   "outputs": [],
   "source": [
    "im = x_train[14]\n",
    "\n",
    "# TODO: get the feature maps for an image\n",
    "# NOTE: you have to reshape the images to include the batch size (equals to 1)\n",
    "feature_maps = ...\n",
    "\n",
    "# Print the shape of feature_maps\n",
    "print(feature_maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "VAO9_5_yhJne",
    "outputId": "8e50a69d-ac4d-4fbf-cc56-578be9368420"
   },
   "outputs": [],
   "source": [
    "# We plot the image for which we want to compute the feature maps and its class\n",
    "plt.imshow(im)\n",
    "print(class_names[y_train[14].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "I6k-GFfKhYh_",
    "outputId": "530c5f21-d6be-4847-8d8c-8212fb979456"
   },
   "outputs": [],
   "source": [
    "# TODO: show the feature map corresponding to the 5th filter as an image\n",
    "# NOTE: Remember that feature_maps.shape = (1, 32, 32, 32) where the 4th entry represents the filters\n",
    "fmap = ...\n",
    "print(fmap.shape)\n",
    "\n",
    "plt.imshow(fmap,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RnT46XikhaCT",
    "outputId": "71ce11a7-e67d-4a71-8bc6-eb4f2d8e7857"
   },
   "outputs": [],
   "source": [
    "# We plot all the feature maps\n",
    "fig  = plt.figure(figsize=(16,8))\n",
    "\n",
    "for i in range(32):\n",
    "    sub = fig.add_subplot(4,8, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    sub.imshow(feature_maps[0,:,:,i], cmap = \"gray\")\n",
    "    sub.set_title(f\"Fieature map {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6yUpaylMULv"
   },
   "source": [
    "### Plot the learned Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "fYDQYwwmMULv",
    "outputId": "5947265c-0310-4c92-f146-1cbc054ccfc2"
   },
   "outputs": [],
   "source": [
    "# TODO: extracting the weights of the first convolutional layer\n",
    "# NOTE: remebere thah for a conv layer the learned weights are the filters !\n",
    "conv_weights, conv_biases = ...\n",
    "\n",
    "# Normalizing the weights to [0, 1] to make them easy to visualize.\n",
    "conv_weights_normalized = (conv_weights - np.min(conv_weights)) / (np.max(conv_weights) - np.min(conv_weights))\n",
    "\n",
    "# Plotting the learned filters\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(conv_weights.shape[-1]):\n",
    "    plt.subplot(6, 6, i + 1)\n",
    "    plt.imshow(conv_weights_normalized[:, :, :, i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Filter {i+1}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
